{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIAK预训练llama3-70b最佳实践\n",
    "\n",
    "本方案旨在帮助大模型开发者快速上手在百舸平台使用AIAK进行大模型训练，以llama3-70b为例演示如何实现大模型预训练。\n",
    "\n",
    "## 步骤一：准备模型权重\n",
    "\n",
    "### 下载权重\n",
    "\n",
    "安装下载工具并下载HF权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://doc.bce.baidu.com/bce-documentation/BOS/linux-bcecmd-0.4.5.zip\n",
    "! apt-get install unzip\n",
    "! unzip linux-bcecmd-0.4.5.zip -d ./\n",
    "! ./linux-bcecmd-0.4.5/bcecmd bos sync bos:/cce-ai-datasets/huggingface.co/meta-llama/Llama-2-70b-hf /root/pfs/models/llama3-70b/modelscope.cn/models/LLM-Research/Meta-Llama-3-70B  --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 权重格式转换\n",
    "权重格式转换，将权重从HF格式转换为MegatronCore格式，提交一个权重转换任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install bce-python-sdk-next==100.9.19.16\n",
    "! pip install future==1.0.0\n",
    "! pip install pycryptodome==3.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from baidubce.services.aihc.aihc_client import AIHCClient\n",
    "\n",
    "import baidubce.protocol\n",
    "from baidubce.bce_client_configuration import BceClientConfiguration\n",
    "from baidubce.auth.bce_credentials import BceCredentials\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载.env文件\n",
    "load_dotenv()\n",
    "\n",
    "# 获取配置信息, 从环境变量中获取,需要先在.env文件中设置环境变量\n",
    "ak = os.getenv(\"AK\")\n",
    "sk = os.getenv(\"SK\")\n",
    "host = os.getenv(\"HOST\")\n",
    "\n",
    "client_token = 'test-aihc-' + str(int(time.time()))\n",
    "logging.info('client_token: %s', client_token)\n",
    "\n",
    "config = BceClientConfiguration(\n",
    "    credentials=BceCredentials(ak, sk),\n",
    "    endpoint=host,\n",
    "    protocol=baidubce.protocol.HTTPS\n",
    ")\n",
    "\n",
    "aihc_client = AIHCClient(config)\n",
    "\n",
    "# 创建任务\n",
    "resourcePoolId = 'cce-e0isdmib'\n",
    "\n",
    "command = r\"\"\"#! /bin/bash\n",
    "\n",
    "AIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n",
    "CONVERT_CHECKPOINT_PATH=\"$AIAK_TRAINING_PATH/tools/convert_checkpoint\"\n",
    "\n",
    "python $CONVERT_CHECKPOINT_PATH/model.py \\\n",
    "    --load_platform=huggingface \\\n",
    "    --save_platform=mcore \\\n",
    "    --common_config_path=$CONVERT_CHECKPOINT_PATH/config/llama2-70b.json \\\n",
    "    --tensor_model_parallel_size=4 \\\n",
    "    --pipeline_model_parallel_size=4 \\\n",
    "    --load_ckpt_path=$LOAD \\\n",
    "    --save_ckpt_path=$SAVE \\\n",
    "    --no_save_optim \\\n",
    "    --no_load_optim\"\"\"\n",
    "\n",
    "payload = {\n",
    "    \"queue\": \"default\",\n",
    "    \"priority\": \"normal\",\n",
    "    \"jobFramework\": \"PyTorchJob\",\n",
    "    \"name\": \"llama2-70b-ck-quickstart-v1\",\n",
    "    \"jobSpec\": {\n",
    "        \"command\": command,\n",
    "        \"image\": \"registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\n",
    "        \"replicas\": 1,\n",
    "        \"envs\": [\n",
    "            {\n",
    "                \"name\":\"LOAD\",\n",
    "                \"value\":\"/root/pfs/models/llama3-70b/modelscope.cn/models/LLM-Research/Meta-Llama-3-70B\"\n",
    "            },\n",
    "                        {\n",
    "                \"name\":\"SAVE\",\n",
    "                \"value\":\"/root/pfs/models/llama3-70b/mcore/modelscope.cn/models/LLM-Research/Meta-Llama-3-70B/tp4_pp4\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"labels\": [\n",
    "            {\n",
    "                \"key\": \"aijob.cce.baidubce.com/ai-user-id\",\n",
    "                \"value\": \"69bb4999b2044af8bbda25aec2f1e1f2\"\n",
    "            },\n",
    "            {\n",
    "                \"key\": \"aijob.cce.baidubce.com/ai-user-name\",\n",
    "                \"value\": \"zhangsan\"\n",
    "            }\n",
    "            ],\n",
    "    \"datasources\": [\n",
    "        {\n",
    "            \"type\": \"pfs\",\n",
    "            \"name\": \"pfs-oYQuh4\",\n",
    "            \"mountPath\": \"/root/pfs\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "res = aihc_client.create_aijob(\n",
    "    client_token=client_token,\n",
    "    resourcePoolId=resourcePoolId,\n",
    "    payload=payload\n",
    ")\n",
    "print('res', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤二：准备预训练数据\n",
    "\n",
    "### 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -o /root/pfs/datasets/WuDaoCorpus2.0_base_sample.tgz https://cce-ai-datasets.cdn.bcebos.com/datasets/aiak/WuDaoCorpus2.0_base_sample.tgz\n",
    "! tar zxvf WuDaoCorpus2.0_base_sample.tgz -C /root/pfs/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据格式转换\n",
    "\n",
    "解压缩后得到10个JSON文件，文件内容为数组对象格式：\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"uniqueKey\": \"da73e2d0bb4e39d241c3806876621da7\",\n",
    "        \"titleUkey\": \"da73e2d0bb4e39d241c3806876621da7\",\n",
    "        \"dataType\": \"博客\",\n",
    "        \"title\": \"引网站蜘蛛的方法\",\n",
    "        \"content\": \"做站长的都希望自已做的网站被搜索引擎比如百度尽早收录。对于新站来说,蜘蛛可没不是呼之即来挥之即去的。 但是也不是一筹莫展,无计可施,只有摸透了这一只只神秘莫测的蜘蛛,有的放矢,才能随心所欲,对吧。呵呵。些话不多说,言归正传吧。 第一,蜘蛛的出动其实是非常讲究效率的,他们也懒得白跑,如果你的网站十天半个月不更新,他白跑几次后,也就不会来这么勤了。 所以,为了让蜘蛛天天来,那么就务必不让他空来,每次都喂点食。所以对策说就是最好每天更新内容了。 可以说,你规律性的多久更新一次,蜘蛛很可能也多久才来一次。 第二,尽量去掉网页上可有可无的部分吧,特别是java之类的,还有过大的图片,要尽量降低网页加载负荷,,加速网页的打开速度,网页打速度快,那么用户体验才好,跳出率才低,网页评分才高。 第三,检查内部链接结构,去除死链接和重复链接；死链接让蜘蛛原地打转,重复连接降低网页的新鲜度； 第四,尽量多从正规和相关站点获得反向链接,正规的链接能确保外链的稳定,以及免收株连；相关链接能提高外链的权重； 第五,为站点制作网站地图,包括格式和xml两种格式,作为蜘蛛爬行的向导,让蜘蛛能爬满整个网站而没有遗漏； 第六,确保服务器返回正确的数据包响应,这条比较玄,还不懂,你可以跟我说下什么意思； 第七、为每个页面制作独立的标题和meta标签(关键字、描述),这个在网页模板里写好调用代码就行； 第八、查看网页日志,监测蜘蛛的的爬行记录,蜘蛛爬行后会留下足迹,查看这些足迹就知道蜘蛛什么时候曾经光顾过这里了。 第九,直接快速的方法:用繁殖池自动繁殖引蜘蛛,它可以快速收录站群链接或者外推链接,可以实现亿万级蜘蛛网互联互串引蜘蛛,可以增加网站收录,提升网站排名。使用繁殖池引蜘蛛到其他平台发布外链不会受到种种限制。 需要繁殖池的联系官方qq: 咨询,马上为您申请开通！\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"uniqueKey\": \"0d78638721aecbdd798a072746114d20\",\n",
    "        \"titleUkey\": \"0d78638721aecbdd798a072746114d20\",\n",
    "        \"dataType\": \"博客\",\n",
    "        \"title\": \"千站云繁殖池收录神器是什么?\",\n",
    "        \"content\": \"千站云繁殖池是一款全新的升级收录算法,全面升级,6大功能,快速收录站群链接或者外推链接,已经取代于蜘蛛池,蜘蛛池的效果差已过时了； 那什么是繁殖池？适用于什么？有什么作用？ 繁殖池是大量网站将百度蜘蛛来访时集成一个池,通过程序控制自动繁殖外链地址给蜘蛛,这样可以快速大量收录站群链接或者外推链接； 适用于医疗媒体外推、站群、泛站、目录群、寄生虫、博客、微博、论坛、b2b信息,全自动繁殖不同地址引蜘蛛,实用而操作简单,效果好,可以实现亿万级蜘蛛网互联互串引蜘蛛,可以让新站、外推链接、媒体链接等等快速增加收录,被k网站也可以尽快恢复权重和搜索引擎快照,正常收录的网站可以增加网站收录,提升网站排名让你感受到不再需要为引蜘蛛到其他平台发布外链而受到种种限制等欢喜； 如果需要可以联系官方qq: 马上申请为你开通！！！\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "需要先将其处理为每行一个完整对象的jsonl格式：\n",
    "\n",
    "```\n",
    "{\"id\":1,\"uniqueKey\":\"da73e2d0bb4e39d241c3806876621da7\",\"titleUkey\":\"da73e2d0bb4e39d241c3806876621da7\",\"dataType\":\"博客\",\"title\":\"引网站蜘蛛的方法\",\"content\":\"做站长的都希望自已做的网站被搜索引擎比如百度尽早收录。对于新站来说,蜘蛛可没不是呼之即来挥之即去的。 但是也不是一筹莫展,无计可施,只有摸透了这一只只神秘莫测的蜘蛛,有的放矢,才能随心所欲,对吧。呵呵。些话不多说,言归正传吧。 第一,蜘蛛的出动其实是非常讲究效率的,他们也懒得白跑,如果你的网站十天半个月不更新,他白跑几次后,也就不会来这么勤了。 所以,为了让蜘蛛天天来,那么就务必不让他空来,每次都喂点食。所以对策说就是最好每天更新内容了。 可以说,你规律性的多久更新一次,蜘蛛很可能也多久才来一次。 第二,尽量去掉网页上可有可无的部分吧,特别是java之类的,还有过大的图片,要尽量降低网页加载负荷,,加速网页的打开速度,网页打速度快,那么用户体验才好,跳出率才低,网页评分才高。 第三,检查内部链接结构,去除死链接和重复链接；死链接让蜘蛛原地打转,重复连接降低网页的新鲜度； 第四,尽量多从正规和相关站点获得反向链接,正规的链接能确保外链的稳定,以及免收株连；相关链接能提高外链的权重； 第五,为站点制作网站地图,包括格式和xml两种格式,作为蜘蛛爬行的向导,让蜘蛛能爬满整个网站而没有遗漏； 第六,确保服务器返回正确的数据包响应,这条比较玄,还不懂,你可以跟我说下什么意思； 第七、为每个页面制作独立的标题和meta标签(关键字、描述),这个在网页模板里写好调用代码就行； 第八、查看网页日志,监测蜘蛛的的爬行记录,蜘蛛爬行后会留下足迹,查看这些足迹就知道蜘蛛什么时候曾经光顾过这里了。 第九,直接快速的方法:用繁殖池自动繁殖引蜘蛛,它可以快速收录站群链接或者外推链接,可以实现亿万级蜘蛛网互联互串引蜘蛛,可以增加网站收录,提升网站排名。使用繁殖池引蜘蛛到其他平台发布外链不会受到种种限制。 需要繁殖池的联系官方qq: 咨询,马上为您申请开通！\"}\n",
    "{\"id\":2,\"uniqueKey\":\"0d78638721aecbdd798a072746114d20\",\"titleUkey\":\"0d78638721aecbdd798a072746114d20\",\"dataType\":\"博客\",\"title\":\"千站云繁殖池收录神器是什么?\",\"content\":\"千站云繁殖池是一款全新的升级收录算法,全面升级,6大功能,快速收录站群链接或者外推链接,已经取代于蜘蛛池,蜘蛛池的效果差已过时了； 那什么是繁殖池？适用于什么？有什么作用？ 繁殖池是大量网站将百度蜘蛛来访时集成一个池,通过程序控制自动繁殖外链地址给蜘蛛,这样可以快速大量收录站群链接或者外推链接； 适用于医疗媒体外推、站群、泛站、目录群、寄生虫、博客、微博、论坛、b2b信息,全自动繁殖不同地址引蜘蛛,实用而操作简单,效果好,可以实现亿万级蜘蛛网互联互串引蜘蛛,可以让新站、外推链接、媒体链接等等快速增加收录,被k网站也可以尽快恢复权重和搜索引擎快照,正常收录的网站可以增加网站收录,提升网站排名让你感受到不再需要为引蜘蛛到其他平台发布外链而受到种种限制等欢喜； 如果需要可以联系官方qq: 马上申请为你开通！！！\"}\n",
    "```\n",
    "\n",
    "> 该数据集约有32201908个tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 定义要保存的jsonl文件名\n",
    "output_file = '/root/pfs/datasets/WuDaoCorpus2.0_base_sample.jsonl'\n",
    "input_dir = '/root/pfs/datasets/WuDaoCorpus2.0_base_sample'\n",
    "# 打开文件准备写入\n",
    "i = 0\n",
    "with open(output_file, 'w') as file:\n",
    "    \n",
    "    # 遍历当前目录下所有的.json文件\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            print(filename)\n",
    "            # 读取json文件内容\n",
    "            with open(input_dir+ '/' +filename, 'r') as json_file:\n",
    "                data_list = json.load(json_file)\n",
    "                # 遍历数据列表\n",
    "                for data in data_list:\n",
    "                    # 将字典转换为JSON字符串\n",
    "                    data['text'] = data['content']\n",
    "                    data['content'] = ''\n",
    "                    json_str = json.dumps(data)\n",
    "                    if len(json_str) < 100:\n",
    "                        print('is null')\n",
    "                    i = i+1\n",
    "                    # if i%100 == 0:\n",
    "                    #     print(json_str)\n",
    "                    # 写入文件，并添加换行符\n",
    "                    if i<10000:\n",
    "                        file.write(json_str + '\\n')\n",
    "                    else:\n",
    "                        file.write(json_str)\n",
    "print(i)                  \n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from baidubce.services.aihc.aihc_client import AIHCClient\n",
    "\n",
    "import baidubce.protocol\n",
    "from baidubce.bce_client_configuration import BceClientConfiguration\n",
    "from baidubce.auth.bce_credentials import BceCredentials\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载.env文件\n",
    "load_dotenv()\n",
    "\n",
    "# 获取配置信息, 从环境变量中获取,需要先在.env文件中设置环境变量\n",
    "ak = os.getenv(\"AK\")\n",
    "sk = os.getenv(\"SK\")\n",
    "host=os.getenv(\"HOST\")\n",
    "\n",
    "client_token = 'test-aihc-' + str(int(time.time()))\n",
    "logging.info('client_token: %s', client_token)\n",
    "\n",
    "config = BceClientConfiguration(\n",
    "    credentials=BceCredentials(ak, sk),\n",
    "    endpoint=host,\n",
    "    protocol=baidubce.protocol.HTTPS\n",
    ")\n",
    "\n",
    "aihc_client = AIHCClient(config)\n",
    "\n",
    "# 创建任务\n",
    "resourcePoolId = 'cce-e0isdmib'\n",
    "command = r\"\"\"#!/bin/bash\n",
    "\n",
    "MEGATRON_PATH=${MEGATRON_PATH:-\"/workspace/AIAK-Megatron\"}\n",
    "AIAK_TRAINING_PATH=${AIAK_TRAINING_PATH:-\"/workspace/AIAK-Training-LLM\"}\n",
    "\n",
    "TOKENIZER_PATH=${TOKENIZER_PATH:-\"/mnt/cluster/huggingface.co/meta-llama/Meta-Llama-3-8B/\"}\n",
    "\n",
    "PYTHONPATH=$MEGATRON_PATH:$AIAK_TRAINING_PATH:$PYTHONPATH \\\n",
    "    python ${AIAK_TRAINING_PATH}/tools/data_preprocess/preprocess_pretrain_data.py \\\n",
    "        --input ${input_data} \\\n",
    "        --output-prefix ${output_prefix} \\\n",
    "        --tokenizer-type HFTokenizer \\\n",
    "        --hf-tokenizer-path $TOKENIZER_PATH \\\n",
    "        --json-keys text \\\n",
    "        --workers 50 \\\n",
    "        --append-eod\"\"\"\n",
    "payload = {\n",
    "    \"queue\": \"default\",\n",
    "    \"priority\": \"normal\",\n",
    "    \"jobFramework\": \"PyTorchJob\",\n",
    "    \"name\": \"llama2-70b-pd-quickstart-v1\",\n",
    "    \"jobSpec\": {\n",
    "        \"command\": command,\n",
    "        \"image\": \"registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\n",
    "        \"replicas\": 1,\n",
    "        \"labels\": [\n",
    "            {\n",
    "                \"key\": \"aijob.cce.baidubce.com/ai-user-id\",\n",
    "                \"value\": \"69bb4999b2044af8bbda25aec2f1e1f2\"\n",
    "            },\n",
    "            {\n",
    "                \"key\": \"aijob.cce.baidubce.com/ai-user-name\",\n",
    "                \"value\": \"zhangsan\"\n",
    "            }\n",
    "            ],\n",
    "        \"envs\": [\n",
    "            {\n",
    "                \"name\": \"TOKENIZER_PATH\",\n",
    "                \"value\": \"/root/pfs/models/llama3-70b/modelscope.cn/models/LLM-Research/Meta-Llama-3-70B\"\n",
    "            },\n",
    "                        {\n",
    "                \"name\": \"input_data\",\n",
    "                \"value\": \"/root/pfs/datasets/WuDaoCorpus2.0_base_sample.jsonl\"\n",
    "            },\n",
    "                        {\n",
    "                \"name\": \"output_prefix\",\n",
    "                \"value\": \"/root/pfs/datasets/WuDaoCorpus2.0_base_sample\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"datasources\": [\n",
    "        {\n",
    "            \"type\": \"pfs\",\n",
    "            \"name\": \"pfs-oYQuh4\",\n",
    "            \"mountPath\": \"/root/pfs\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "res = aihc_client.create_aijob(\n",
    "    client_token=client_token,\n",
    "    resourcePoolId=resourcePoolId,\n",
    "    payload=payload\n",
    ")\n",
    "print('res', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 步骤三：使用AIAK提交训练任务\n",
    "\n",
    "### 预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from baidubce.services.aihc.aihc_client import AIHCClient\n",
    "\n",
    "import baidubce.protocol\n",
    "from baidubce.bce_client_configuration import BceClientConfiguration\n",
    "from baidubce.auth.bce_credentials import BceCredentials\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载.env文件\n",
    "load_dotenv()\n",
    "\n",
    "# 获取配置信息, 从环境变量中获取,需要先在.env文件中设置环境变量\n",
    "ak = os.getenv(\"AK\")\n",
    "sk = os.getenv(\"SK\")\n",
    "host=os.getenv(\"HOST\")\n",
    "\n",
    "print(ak)\n",
    "print(sk)\n",
    "\n",
    "client_token = 'test-aihc-' + str(int(time.time()))\n",
    "logging.info('client_token: %s', client_token)\n",
    "\n",
    "config = BceClientConfiguration(\n",
    "    credentials=BceCredentials(ak, sk),\n",
    "    endpoint=host,\n",
    "    protocol=baidubce.protocol.HTTPS\n",
    ")\n",
    "\n",
    "aihc_client = AIHCClient(config)\n",
    "\n",
    "# 创建任务\n",
    "resourcePoolId = 'cce-e0isdmib'\n",
    "payload = {\n",
    "    \"queue\": \"default\",\n",
    "    \"priority\": \"normal\",\n",
    "    \"jobFramework\": \"PyTorchJob\",\n",
    "    \"name\": \"llama2-70b-train-quickstart-v1\",\n",
    "    \"jobSpec\": {\n",
    "        \"command\": \"bash /workspace/AIAK-Training-LLM/examples/llama2/pretrain/pretrain_llama2_70b.sh\",\n",
    "        \"image\": \"registry.baidubce.com/aihc-aiak/aiak-training-llm:ubuntu22.04-cu12.3-torch2.2.0-py310-bccl1.2.7.2_v2.1.1.5_release\",\n",
    "        \"replicas\": 4,\n",
    "        \"resources\": [\n",
    "            {\n",
    "                \"name\": \"baidu.com/a800_80g_cgpu\",\n",
    "                \"quantity\": 8\n",
    "            }\n",
    "        ],\n",
    "        \"enableRDMA\": True,\n",
    "        \"labels\": [\n",
    "            {\n",
    "                \"key\": \"aijob.cce.baidubce.com/ai-user-id\",\n",
    "                \"value\": \"69bb4999b2044af8bbda25aec2f1e1f2\"\n",
    "            },\n",
    "            {\n",
    "                \"key\": \"aijob.cce.baidubce.com/ai-user-name\",\n",
    "                \"value\": \"zhangsan\"\n",
    "            }\n",
    "            ],\n",
    "        \"envs\": [\n",
    "            {\n",
    "                \"name\": \"CUDA_DEVICE_MAX_CONNECTIONS\",\n",
    "                \"value\": \"1\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"DATA_PATH\",\n",
    "                \"value\": \"/root/pfs/datasets/WuDaoCorpus2.0_base_sample_text_document\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"TOKENIZER_PATH\",\n",
    "                \"value\": \"/root/pfs/models/llama3-70b/modelscope.cn/models/LLM-Research/Meta-Llama-3-70B\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"CHECKPOINT_PATH\",\n",
    "                \"value\": \"/root/pfs/models/llama3-70b/mcore/modelscope.cn/models/LLM-Research/Meta-Llama-3-70B/tp4_pp4\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"datasources\": [\n",
    "        {\n",
    "            \"type\": \"pfs\",\n",
    "            \"name\": \"pfs-oYQuh4\",\n",
    "            \"mountPath\": \"/root/pfs\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "res = aihc_client.create_aijob(\n",
    "    client_token=client_token,\n",
    "    resourcePoolId=resourcePoolId,\n",
    "    payload=payload\n",
    ")\n",
    "print('res', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤四：模型格式转换\n",
    "您可以将训练获得的Megatron格式的模型转换为Huggingface格式，具体操作步骤如下。后续您可以使用转换后的Huggingface格式的模型进行服务在线部署。\n",
    "\n",
    "## 步骤五：部署及调用模型服务\n",
    "完成离线推理并评估完成模型效果后，您可以将转换为Huggingface格式的模型部署为在线服务，并在实际的生产环境中调用，从而进行推理实践。具体操作步骤如下："
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
