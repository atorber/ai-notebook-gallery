{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixtral-8x7B稀疏大模型最佳实践\n",
    "\n",
    "本方案旨在帮助大模型开发者快速上手平台，实现稀疏大语言模型Mixtral的高效分布式训练、三阶段指令微调、模型离线推理和在线服务部署等完整的开发流程。以Mixtral-8x7B模型为例，为您详细介绍该方案的开发流程。\n",
    "\n",
    "## 步骤一：准备Mixtral-8x7B-v0.1\n",
    "\n",
    "1. 从ModelScope社区下载权重，安装下载工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install modelscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 执行以下命令下载示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Loading Model and Tokenizer\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "model_dir = snapshot_download('AI-ModelScope/Mixtral-8x7B-v0.1', 'v1.1.4')\n",
    "# 获取下载路径\n",
    "print(model_dir)\n",
    "# model_dir = snapshot_download('AI-ModelScope/Mixtral-8x7B-Instruct-v0.1', 'v1.1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 控制台执行以下命令\n",
    "\n",
    "    ```basj\n",
    "    # mkdir -p /mnt/workspace/mixtral-ckpts/${后缀为hf的ckpt文件夹}\n",
    "    mkdir -p /mnt/workspace/mixtral-ckpts/Mixtral-8x7B-v0.1\n",
    "    # cp -r ${在此处填写已下载的模型路径}/* /mnt/workspace/mixtral-ckpts/${后缀为hf的ckpt文件夹}。\n",
    "    cp -r /root/.cache/modelscope/hub/mixtral/Mixtral-8x7B-v0.1/* /mnt/workspace/mixtral-ckpts/Mixtral-8x7B-v0.1\n",
    "    ```\n",
    "\n",
    "## 步骤二：准备预训练数据\n",
    "建议您在DSW实例中准备预训练数据。本案例以WuDaoCorpora2.0数据集（该数据集仅供研究使用）为例，介绍Megatron训练数据的预处理流程。\n",
    "\n",
    "    ```bash\n",
    "    mkdir /mnt/workspace/mixtral-datasets/\n",
    "    cd /mnt/workspace/mixtral-datasets\n",
    "    wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/mistral-datasets/alpaca_zh-mistral-train.json\n",
    "    wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/mistral-datasets/alpaca_zh-mistral-valid.json\n",
    "    mkdir -p /mnt/workspace/mixtral-datasets/wudao\n",
    "    cd /mnt/workspace/mixtral-datasets/wudao\n",
    "    wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/mistral-datasets/wudao_mistralbpe_content_document.idx\n",
    "    wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/mistral-datasets/wudao_mistralbpe_content_document.bin\n",
    "    ```\n",
    "\n",
    "## 步骤三：Megatron训练\n",
    "您可以按照以下流程进行Megatron训练。\n",
    "\n",
    "### 模型格式转换\n",
    "将Huggingface格式的模型文件转换为Megatron格式。\n",
    "\n",
    "    ```\n",
    "    cd /mnt/workspace/\n",
    "    mkdir mixtral-ckpts\n",
    "    cd mixtral-ckpts\n",
    "    wget https://atp-modelzoo-wlcb-pai.oss-cn-wulanchabu.aliyuncs.com/release/models/pai-megatron-patch/mistral-ckpts/Mixtral-8x7B-v0.1-to-mcore-tp4-ep4.tar.zst\n",
    "    tar -zxf Mixtral-8x7B-v0.1-to-mcore-tp4-ep4.tar.zst\n",
    "    ```\n",
    "\n",
    "### 预训练模型\n",
    "您可以在DSW单机环境中训练模型，也可以在DLC环境中提交多机多卡分布式训练任务，训练过程大约持续2个小时。任务执行成功后，模型文件将输出到/mnt/workspace/output_megatron_mixtral/目录下。\n",
    "\n",
    "## 步骤四：模型格式转换\n",
    "您可以将训练获得的Megatron格式的模型转换为Huggingface格式，具体操作步骤如下。后续您可以使用转换后的Huggingface格式的模型进行服务在线部署。\n",
    "\n",
    "## 步骤五：部署及调用模型服务\n",
    "完成离线推理并评估完成模型效果后，您可以将转换为Huggingface格式的模型部署为在线服务，并在实际的生产环境中调用，从而进行推理实践。具体操作步骤如下："
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
